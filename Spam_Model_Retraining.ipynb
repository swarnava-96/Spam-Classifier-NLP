{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam Model Retraining",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KlEy-dH4GoJ9nqJ9XG80UvnY-NqHGECc",
      "authorship_tag": "ABX9TyNkY0uhhzA9jXeeIMG/cvI8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarnava-96/Spam-Classifier-NLP-ML/blob/main/Spam_Model_Retraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tli_YR27LWO"
      },
      "source": [
        "# **Incremetal Model Retraining**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI-IL3KS9Rug",
        "outputId": "c499a736-729b-4634-a069-61e976068b37"
      },
      "source": [
        "# Lets install creme\n",
        "!pip install creme"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting creme\n",
            "  Downloading creme-0.6.1-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from creme) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from creme) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from creme) (1.19.5)\n",
            "Collecting mmh3==2.5.1\n",
            "  Downloading mmh3-2.5.1.tar.gz (9.8 kB)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->creme) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->creme) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->creme) (1.15.0)\n",
            "Building wheels for collected packages: mmh3\n",
            "  Building wheel for mmh3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmh3: filename=mmh3-2.5.1-cp37-cp37m-linux_x86_64.whl size=39690 sha256=e47820c2b06cb6f009833c7a280d60557298c3eb720769f8891762912b436a25\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/45/25/90e097a519143b2dca74cd93a056894a965f27908103e01799\n",
            "Successfully built mmh3\n",
            "Installing collected packages: mmh3, creme\n",
            "Successfully installed creme-0.6.1 mmh3-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9_THL0i7Q0G"
      },
      "source": [
        "# Loading the data\n",
        "import pandas as pd\n",
        "\n",
        "messages = pd.read_csv('/content/SMSSpamCollection', sep='\\t',\n",
        "                           names=[\"label\", \"message\"])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fo1mWLU7X27",
        "outputId": "fa83c8fb-8797-404c-9236-1c00b160fa64"
      },
      "source": [
        "# Lets check the shape of the data\n",
        "messages.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uJklTa88VE9"
      },
      "source": [
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "message_train, message_test = train_test_split(messages)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "bmYuUdnV8ihq",
        "outputId": "dfe49c3e-7a69-4a12-b145-7ee9714dcef5"
      },
      "source": [
        "# Lets see the training data\n",
        "message_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>ham</td>\n",
              "      <td>O was not into fps then.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1340</th>\n",
              "      <td>ham</td>\n",
              "      <td>Every monday..nxt week vl be completing..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1855</th>\n",
              "      <td>ham</td>\n",
              "      <td>They did't play one day last year know even th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2312</th>\n",
              "      <td>spam</td>\n",
              "      <td>Congratulations! Thanks to a good friend U hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4600</th>\n",
              "      <td>ham</td>\n",
              "      <td>Have you laid your airtel line to rest?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>ham</td>\n",
              "      <td>Save yourself the stress. If the person has a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1930</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free 1st week entry 2 TEXTPOD 4 a chance 2 win...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3631</th>\n",
              "      <td>spam</td>\n",
              "      <td>Get the official ENGLAND poly ringtone or colo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1565</th>\n",
              "      <td>ham</td>\n",
              "      <td>Tmrw. Im finishing 9 doors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4871</th>\n",
              "      <td>ham</td>\n",
              "      <td>Dip's cell dead. So i m coming with him. U bet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4179 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                            message\n",
              "2415   ham                           O was not into fps then.\n",
              "1340   ham          Every monday..nxt week vl be completing..\n",
              "1855   ham  They did't play one day last year know even th...\n",
              "2312  spam  Congratulations! Thanks to a good friend U hav...\n",
              "4600   ham            Have you laid your airtel line to rest?\n",
              "...    ...                                                ...\n",
              "714    ham  Save yourself the stress. If the person has a ...\n",
              "1930  spam  Free 1st week entry 2 TEXTPOD 4 a chance 2 win...\n",
              "3631  spam  Get the official ENGLAND poly ringtone or colo...\n",
              "1565   ham                         Tmrw. Im finishing 9 doors\n",
              "4871   ham  Dip's cell dead. So i m coming with him. U bet...\n",
              "\n",
              "[4179 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72a_KnSe8nvP"
      },
      "source": [
        "# Converting the dataset into tuples\n",
        "messages_train = message_train.to_records(index = False)\n",
        "messages_test = message_test.to_records(index = False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozOFnzea9ARi",
        "outputId": "688165e6-422a-4e55-a186-c62974bcf198"
      },
      "source": [
        "# Lets see our tuple\n",
        "messages_train"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rec.array([('ham', 'O was not into fps then.'),\n",
              "           ('ham', 'Every monday..nxt week vl be completing..'),\n",
              "           ('ham', \"They did't play one day last year know even though they have very good team.. Like india.\"),\n",
              "           ...,\n",
              "           ('spam', 'Get the official ENGLAND poly ringtone or colour flag on yer mobile for tonights game! Text TONE or FLAG to 84199. Optout txt ENG STOP Box39822 W111WX £1.50'),\n",
              "           ('ham', 'Tmrw. Im finishing 9 doors'),\n",
              "           ('ham', \"Dip's cell dead. So i m coming with him. U better respond else we shall come back.\")],\n",
              "          dtype=[('label', 'O'), ('message', 'O')])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McdGs8Kh9E12"
      },
      "source": [
        "# Creating the pipeline\n",
        "# 1st function is creating the TFIDF\n",
        "# 2nd function is the naive bayes predictor\n",
        "\n",
        "import creme\n",
        "import math\n",
        "from creme import compose\n",
        "from creme import feature_extraction\n",
        "from creme import naive_bayes\n",
        "\n",
        "model = compose.Pipeline(\n",
        "    (\"tokenize\", feature_extraction.TFIDF(lowercase = False)),\n",
        "    (\"nb\",naive_bayes.MultinomialNB(alpha = 1))\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1J0ptZt9Plo"
      },
      "source": [
        "from creme import metrics\n",
        "metric = metrics.Accuracy()\n",
        "\n",
        "# Training the model row by row\n",
        "for label, sentence in messages_train:\n",
        "  model = model.fit_one(sentence, label)\n",
        "  y_pred = model.predict_one(sentence)\n",
        "  metric = metric.update(label, y_pred)  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pW8_wIu-00y",
        "outputId": "6231f09b-5a18-4a46-ba82-daa9bce92a31"
      },
      "source": [
        "# Lets see the training data accuracy\n",
        "metric"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Accuracy: 95.93%"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBowPe9G-6vg"
      },
      "source": [
        "# Test data accuracy\n",
        "test_metric = metrics.Accuracy()\n",
        "for label,sentence in messages_test:\n",
        "  y_pred = model.predict_one(sentence)\n",
        "  test_metric = metric.update(label,y_pred)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmP-XCIZ_USh",
        "outputId": "d20a2866-0cd7-4c0d-a611-5c918e7e78f6"
      },
      "source": [
        "# Lets see the test metric\n",
        "metric"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Accuracy: 95.76%"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tLGa4sC_aOw",
        "outputId": "3e93f501-61c3-4e2e-ab49-dca9f17d31c5"
      },
      "source": [
        "# New data\n",
        "model.fit_one(\"This guy is neutral\",\"ham\")\n",
        "model.fit_one(\"Everybody is neutral\",\"ham\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline (\n",
              "  TFIDF (\n",
              "    normalize=True\n",
              "    on=None\n",
              "    strip_accents=True\n",
              "    lowercase=False\n",
              "    preprocessor=None\n",
              "    tokenizer=<built-in method findall of re.Pattern object at 0x7fdc72a0f850>\n",
              "    ngram_range=(1, 1)\n",
              "  ),\n",
              "  MultinomialNB (\n",
              "    alpha=1\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}